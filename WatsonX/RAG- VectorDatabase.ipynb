{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75393fe5",
   "metadata": {},
   "source": [
    "# This Note showcases the RAG usecase\n",
    "- Uses Langchain\n",
    "- FAISS vector Store\n",
    "- Demonstrates, how to split the documents into multiple chuncks\n",
    "- Demonstrates, how to query the embedings from the vector store\n",
    "- Demostrates, calling BAM models for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33dac4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Users/sahil/anaconda3/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (1.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (0.10.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (1.12.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (4.20.1)\n",
      "Requirement already satisfied: numpy in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (1.2.1)\n",
      "Requirement already satisfied: nltk in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (3.7)\n",
      "Requirement already satisfied: tqdm in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: torchvision in /Users/sahil/anaconda3/lib/python3.10/site-packages (from sentence_transformers) (0.14.1a0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (22.0)\n",
      "Requirement already satisfied: filelock in /Users/sahil/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.7.1)\n",
      "Requirement already satisfied: requests in /Users/sahil/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.11.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /Users/sahil/anaconda3/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.1.1)\n",
      "Requirement already satisfied: click in /Users/sahil/anaconda3/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Collecting InstructorEmbedding\n",
      "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: InstructorEmbedding\n",
      "Successfully installed InstructorEmbedding-1.0.1\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.200-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Collecting langchainplus-sdk>=0.0.9\n",
      "  Downloading langchainplus_sdk-0.0.10-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from langchain) (1.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: frozenlist>=1.1.1 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: typing-inspect, tenacity, marshmallow, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, dataclasses-json, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "Successfully installed dataclasses-json-0.5.8 langchain-0.0.200 langchainplus-sdk-0.0.10 marshmallow-3.19.0 marshmallow-enum-1.5.1 openapi-schema-pydantic-1.2.4 tenacity-8.2.2 typing-inspect-0.9.0\n",
      "Collecting ibm-generative-ai\n",
      "  Downloading ibm_generative_ai-0.1.15-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: pyyaml>=0.2.5 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from ibm-generative-ai) (6.0)\n",
      "Collecting python-dotenv>=1.0.0\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: httpx>=0.24.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from ibm-generative-ai) (0.24.1)\n",
      "Collecting aiolimiter>=1.0.0\n",
      "  Downloading aiolimiter-1.1.0-py3-none-any.whl (7.2 kB)\n",
      "Requirement already satisfied: aiohttp>=3.8.4 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from ibm-generative-ai) (3.8.4)\n",
      "Collecting tqdm>=4.65.0\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: requests>=2.28.2 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from ibm-generative-ai) (2.31.0)\n",
      "Requirement already satisfied: urllib3<2 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from ibm-generative-ai) (1.26.14)\n",
      "Collecting pydantic>=1.10.6\n",
      "  Downloading pydantic-1.10.9-cp310-cp310-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp>=3.8.4->ibm-generative-ai) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp>=3.8.4->ibm-generative-ai) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp>=3.8.4->ibm-generative-ai) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp>=3.8.4->ibm-generative-ai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp>=3.8.4->ibm-generative-ai) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp>=3.8.4->ibm-generative-ai) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from aiohttp>=3.8.4->ibm-generative-ai) (2.0.4)\n",
      "Requirement already satisfied: certifi in /Users/sahil/anaconda3/lib/python3.10/site-packages (from httpx>=0.24.0->ibm-generative-ai) (2023.5.7)\n",
      "Requirement already satisfied: sniffio in /Users/sahil/anaconda3/lib/python3.10/site-packages (from httpx>=0.24.0->ibm-generative-ai) (1.2.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from httpx>=0.24.0->ibm-generative-ai) (0.17.2)\n",
      "Requirement already satisfied: idna in /Users/sahil/anaconda3/lib/python3.10/site-packages (from httpx>=0.24.0->ibm-generative-ai) (3.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from pydantic>=1.10.6->ibm-generative-ai) (4.4.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx>=0.24.0->ibm-generative-ai) (3.5.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sahil/anaconda3/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx>=0.24.0->ibm-generative-ai) (0.14.0)\n",
      "Installing collected packages: tqdm, python-dotenv, pydantic, aiolimiter, ibm-generative-ai\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.8.2\n",
      "    Uninstalling pydantic-1.8.2:\n",
      "      Successfully uninstalled pydantic-1.8.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "peft 0.4.0.dev0 requires torch>=1.13.0, but you have torch 1.12.1 which is incompatible.\n",
      "gradio 3.23.0 requires huggingface-hub>=0.13.0, but you have huggingface-hub 0.10.1 which is incompatible.\n",
      "allennlp 2.10.1 requires spacy<3.4,>=2.1.0, but you have spacy 3.5.0 which is incompatible.\n",
      "allennlp 2.10.1 requires torchvision<0.14.0,>=0.8.1, but you have torchvision 0.14.1a0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiolimiter-1.1.0 ibm-generative-ai-0.1.15 pydantic-1.10.9 python-dotenv-1.0.0 tqdm-4.65.0\n",
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.5.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sahil/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - faiss\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    faiss-1.7.4                |py310h2129542_0_cpu         1.2 MB  conda-forge\n",
      "    libblas-3.9.0              |16_osx64_openblas          13 KB  conda-forge\n",
      "    libcxx-16.0.5              |       hd57cbcb_0         1.1 MB  conda-forge\n",
      "    libfaiss-1.7.4             |   h335e8f1_0_cpu         1.3 MB  conda-forge\n",
      "    libfaiss-avx2-1.7.4        |   h1234567_0_cpu         1.4 MB  conda-forge\n",
      "    liblapack-3.9.0            |16_osx64_openblas          13 KB  conda-forge\n",
      "    llvm-openmp-16.0.5         |       hff08bdf_0         289 KB  conda-forge\n",
      "    openssl-1.1.1u             |       h8a1eda9_0         1.7 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  faiss              conda-forge/osx-64::faiss-1.7.4-py310h2129542_0_cpu \n",
      "  libblas            conda-forge/osx-64::libblas-3.9.0-16_osx64_openblas \n",
      "  libfaiss           conda-forge/osx-64::libfaiss-1.7.4-h335e8f1_0_cpu \n",
      "  libfaiss-avx2      conda-forge/osx-64::libfaiss-avx2-1.7.4-h1234567_0_cpu \n",
      "  liblapack          conda-forge/osx-64::liblapack-3.9.0-16_osx64_openblas \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  libcxx                pkgs/main::libcxx-14.0.6-h9765a3e_0 --> conda-forge::libcxx-16.0.5-hd57cbcb_0 \n",
      "  llvm-openmp        pkgs/main::llvm-openmp-14.0.6-h0dcd29~ --> conda-forge::llvm-openmp-16.0.5-hff08bdf_0 \n",
      "  openssl                                 1.1.1t-hfd90126_0 --> 1.1.1u-h8a1eda9_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libfaiss-avx2-1.7.4  | 1.4 MB    |                                       |   0% \n",
      "libblas-3.9.0        | 13 KB     |                                       |   0% \u001b[A\n",
      "\n",
      "libfaiss-1.7.4       | 1.3 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "openssl-1.1.1u       | 1.7 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-16.0.5   | 289 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcxx-16.0.5        | 1.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 13 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.2 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-16.0.5   | 289 KB    | ##                                    |   6% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "libblas-3.9.0        | 13 KB     | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "openssl-1.1.1u       | 1.7 MB    | 3                                     |   1% \u001b[A\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libfaiss-1.7.4       | 1.3 MB    | 4                                     |   1% \u001b[A\u001b[A\n",
      "libblas-3.9.0        | 13 KB     | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcxx-16.0.5        | 1.1 MB    | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "openssl-1.1.1u       | 1.7 MB    | #########7                            |  26% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-1.7.4       | 1.3 MB    | ##########                            |  27% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-16.0.5   | 289 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-16.0.5   | 289 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcxx-16.0.5        | 1.1 MB    | ###########6                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-1.7.4       | 1.3 MB    | #############################2        |  79% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "openssl-1.1.1u       | 1.7 MB    | ################################8     |  89% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 1.4 MB    | ################9                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 13 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "openssl-1.1.1u       | 1.7 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-1.7.4       | 1.3 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "liblapack-3.9.0      | 13 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 1.4 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.2 MB    | ###8                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.2 MB    | ######7                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.2 MB    | ##########6                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.2 MB    | ##############5                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.2 MB    | ###################3                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libcxx-16.0.5        | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.2 MB    | ##########################1           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install InstructorEmbedding\n",
    "!pip install langchain\n",
    "!pip install ibm-generative-ai\n",
    "!conda install -c conda-forge faiss -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610eb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "#BAM\n",
    "from genai.extensions.langchain import LangChainInterface\n",
    "from genai.schemas import ModelType, GenerateParams\n",
    "from genai.model import Credentials\n",
    "\n",
    "import getpass\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b58eb",
   "metadata": {},
   "source": [
    "## Pass Watsonx.ai API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005a9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"your-token-key\"\n",
    "my_api_endpoint=\"https://fmaas-dev-api.bx.cloud9.ibm.com/v1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ff2c2",
   "metadata": {},
   "source": [
    "## Global settings\n",
    "\n",
    "- chunksize: size of chunks documents need to be splited\n",
    "- chunk_overlap: overlap of the chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07e143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 2000\n",
    "chunk_overlap = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f67148a",
   "metadata": {},
   "source": [
    "## Loading the pdf, file using the PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e04e89e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sahil/Downloads/data\n"
     ]
    }
   ],
   "source": [
    "cd /Users/sahil/Downloads/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aecc07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"range_data.pdf\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67ff03",
   "metadata": {},
   "source": [
    "## Total number of documents (pages) in the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "451c47c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 84 document(s) in your data\n"
     ]
    }
   ],
   "source": [
    "#every page in pdf is counted as unique document\n",
    "print (f'You have {len(data)} document(s) in your data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a383ac",
   "metadata": {},
   "source": [
    "## Printing the first page of the pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75284a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 109 characters in first page\n",
      "content of first page\n",
      " : imagine the possibilities\n",
      "Thank you for purchasing this Samsung product.Microwave Oven\n",
      "user manualME19R7041F*\n"
     ]
    }
   ],
   "source": [
    "print (f'There are {len(data[0].page_content)} characters in first page')\n",
    "print(f\"content of first page\\n : {data[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559449c3",
   "metadata": {},
   "source": [
    "## Spliting the documents into multiple chuncks on the chunk size mentioned earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a93793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size= chunk_size, chunk_overlap=chunk_overlap)\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be2672de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have total documents after split: 191\n"
     ]
    }
   ],
   "source": [
    "print(f'We have total documents after split: {len(docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f6263",
   "metadata": {},
   "source": [
    "## Loading Hugging Face Emedings\n",
    "- When you run the below cell for the first time, it does take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bd0c326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac4ccebb322439687a54935c4c6f9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68df102996414ebdba1eeab221a00a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ea8dc53e38492197da9bdeb327afb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b5d7108262480eb17c3822028ee959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621b79d0eb4e4457816246dfcebc4a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/66.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec0fb4985c44395854f7f1bb26f3c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac1ef1f5334415ea247e2a7361b3c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943d788224834e3b8d0853e08acc2233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b584926d44c148f1ab5b34dde1d47220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb33c3de44b4fb18cecf44c35a6218e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c3de37abdb44d99c9110c2fa40cd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c036bd97dd834fe68d551b67d45eaa41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3a79bc7491485ba854fd0aec4139e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a7e6f52edd41f1ad8b3abdcd24adb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "            model_name=\"hkunlp/instructor-large\",\n",
    "            model_kwargs={\"device\": \"cpu\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee5cedd",
   "metadata": {},
   "source": [
    "## Vector Store- FAISS\n",
    "- We have our documents and embedding ready.\n",
    "- Here we are storing our embeddings and docs in the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92fb3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html?highlight=faiss#faiss\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436e824",
   "metadata": {},
   "source": [
    "## Lets test our embeddings\n",
    "- We are passing the query, and looking for the closest 3 embedings.\n",
    "- printing out the closest 3 embedings for the query from the documents or pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00aaf383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "English - 3IMPORTANT SAFETY \n",
      "INSTRUCTIONS\n",
      "When using any electrical appliance, basic safety \n",
      "precautions should be followed, including the following:\n",
      "WARNING WARNING\n",
      "To reduce risk of burns, electric shock, fire, personal \n",
      "injury or exposure to excessive microwave energy:\n",
      "1. Read all safety instructions before using the \n",
      "appliance.\n",
      "2. Read and follow the specific “Precautions to avoid \n",
      "possible exposure to excessive microwave energy” on \n",
      "this page.\n",
      "3. This appliance must be grounded. Connect only to \n",
      "properly grounded outlets. See Important “Grounding \n",
      "instructions” on page 4 of this manual.\n",
      "4. Install or locate this appliance only in accordance with \n",
      "the provided installation instructions.\n",
      "5. Some products such as whole eggs and sealed \n",
      "containers (for example, sealed glass jars), can \n",
      "explode if heated rapidly. Never heat them in a \n",
      "microwave oven.\n",
      "6. Use this appliance only for its intended use as \n",
      "described in the manual. Do not put corrosive \n",
      "chemicals or vapors in or on this appliance. This type \n",
      "of oven is specifically designed to heat, cook, or dry \n",
      "food. It is not designed for industrial or laboratory use.\n",
      "7. As with any appliance, close supervision is necessary \n",
      "when it is used by children.\n",
      "8. Do not operate this appliance if it has a damaged \n",
      "power cord or plug, if it is not working properly, or if it \n",
      "has been damaged or dropped.\n",
      "9. This appliance should be repaired or serviced only \n",
      "by qualified service personnel. Contact the nearest \n",
      "authorized service facility for examination, repair, or \n",
      "adjustment.\n",
      "10. Do not cover or block any openings on the appliance.\n",
      "11. Do not tamper with or make any adjustments or \n",
      "repairs to the door.\n",
      "12. Do not store this appliance outdoors. Do not use this \n",
      "product near water, for example, near a kitchen sink, \n",
      "in a wet basement, near a swimming pool, or similar \n",
      "locations.\n",
      "13. Do not immerse the power cord or plug in water.\n",
      "14. Keep the cord away from heated surfaces. (including \n",
      "the back of the oven).\n",
      "----\n",
      "English - 19\n",
      "04  COOKING GUIDECOOKING SEAFOOD \n",
      "Place the fish on a microwave-safe roasting rack in a \n",
      "microwave-safe dish. Use a tight cover to steam the fish. \n",
      "A lighter cover of wax paper or paper towel will decrease \n",
      "steaming. Cook the fish until it flakes easily with a fork. Do \n",
      "not over cook fish. Check it after the minimum cooking \n",
      "time.\n",
      "FoodCooking time/\n",
      "power levelInstructions\n",
      "Tuna steaks \n",
      "and salmon \n",
      "steaks \n",
      "Up to 1.5 \n",
      "lbs.Cooking \n",
      "Time:\n",
      "6-10 min. / lb. Arrange the steaks on \n",
      "a roasting rack with the \n",
      "meaty portions towards \n",
      "the outside of the rack. \n",
      "Cover with wax paper. \n",
      "Turn them over halfway \n",
      "through the cooking \n",
      "process. Cook until the \n",
      "fish flakes easily with \n",
      "a fork. Let stand for \n",
      "3-5 minutes.Power Level:\n",
      "Medium-High \n",
      "(7).\n",
      "Fillets\n",
      "Up to 1.5 \n",
      "lbs.Cooking \n",
      "Time:\n",
      "4-8 min. / lb.Arrange the fillets in a \n",
      "baking dish, tucking \n",
      "any thin pieces under. \n",
      "Cover with wax paper. \n",
      "If the fillets are thicker \n",
      "than ½ in., turn them \n",
      "over halfway through the \n",
      "cooking process. Cook \n",
      "until the fish flakes easily \n",
      "with a fork. Let stand for \n",
      "2-3 minutes.Power Level:\n",
      "Medium-High \n",
      "(7).\n",
      "Shrimp\n",
      "Up to 1.5 \n",
      "lbs.Cooking \n",
      "Time:\n",
      "4-6 min. / lb.Arrange the shrimp in \n",
      "a baking dish without \n",
      "overlapping or layering \n",
      "them. Cover with wax \n",
      "paper. Cook until firm \n",
      "and opaque, stirring 2 \n",
      "or 3 times. Let stand for \n",
      "5 minutes.Power Level:\n",
      "Medium-High \n",
      "(7).\n",
      "COOKING EGGS \n",
      "You can use your microwave oven to cook eggs. Cook \n",
      "them until they are just set as they become tough if they \n",
      "are overcooked.\n",
      "WARNINGNever cook eggs in their shells and never warm \n",
      "up hard-boiled eggs in their shells. Eggs cooked \n",
      "or warmed up in their shells can explode. Always \n",
      "pierce whole eggs to keep them from bursting.\n",
      "COOKING VEGETABLES\n",
      "Vegetables should be washed prior to cooking. Usually, \n",
      "no extra water is needed. When cooking dense vegetables \n",
      "such as potatoes, carrots, and green beans, add about ¼ \n",
      "cup water.\n",
      "Small vegetables (sliced carrots, peas, lima beans, etc.) \n",
      "will cook faster than larger ones.\n",
      "----\n",
      "English - 15\n",
      "02  USING YOUR MICROWAVE OVENMenu / Item No. / Amount Remarks\n",
      "Sn-5Frozen  \n",
      "Cheese sticks11 serving  \n",
      "(5-6 pcs)Place the cheese sticks on a plate in a spoke-like fashion. Do not cover.\n",
      "Let stand for 1 to 2 minutes after heating.\n",
      "22 servings  \n",
      "(7-8 pcs)\n",
      "Sn-6Chicken wings \n",
      "(refrigerated)11 serving  \n",
      "(5-6 oz)Use precooked, refrigerated chicken wings.\n",
      "Place the chicken wings around the plate in a spoke-like fashion and \n",
      "cover with wax paper.\n",
      "Let stand for 1 to 2 minutes. 22 servings  \n",
      "(7-8 oz)\n",
      "Sn-7 Nachos 11 serving  \n",
      "(8-10 ea)Place the nachos on a plate without letting them overlap. Sprinkle \n",
      "cheese evenly over them.\n",
      "Contents:\n",
      "8-10 ea tortilla chips\n",
      "¼ cup grated cheese\n",
      "Sn-8 Potato skins11  cooked \n",
      "potatoCut the cooked potato into 4 even wedges. Scoop or cut out the potato \n",
      "flesh, leaving about a ¼ in. of skin.\n",
      "Place the skins in a spoke-like fashion around the plate.\n",
      "Sprinkle with bacon, onions and cheese.\n",
      "Do not cover.\n",
      "Let stand 1 to 2 minutes.22  cooked \n",
      "potato\n",
      "MICROWAVE COOKING TIMES & POWER LEVELS\n",
      "Your oven allows you to set two different cooking stages, each with its own time length and power level. The power level lets you \n",
      "control the heating intensity from Warm (1) to High (10).\n",
      "One-stage cooking\n",
      "For simple, one-stage cooking with the power level set to High (10), you only need to set the cooking time, and then \n",
      "press OK/START . The power level is automatically set to High. If you want to set the power level to any other level, use \n",
      "the Power Level  button.\n",
      "1. Use the number buttons to set a cooking time. You can enter a time from one second to 99 minutes and \n",
      "99 seconds. To select a time greater than one minute, enter the seconds too. (For example, to set a cooking time \n",
      "of 20 minutes, enter 2, 0, 0, 0.)\n",
      "2. If you want to set the power level to a level other than High, press the Power Level  button, and then use the \n",
      "number buttons to enter the power level.\n"
     ]
    }
   ],
   "source": [
    "query = \"How to cook eggs\"\n",
    "docs = db.similarity_search(query, k=3)\n",
    "print(len(docs))\n",
    "print(docs[0].page_content)\n",
    "print(\"----\")\n",
    "print(docs[1].page_content)\n",
    "print(\"----\")\n",
    "print(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb9969",
   "metadata": {},
   "source": [
    "## Creating LLM model\n",
    "- Here we are using LangChainInterface to create out BAM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec784c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_llm = LangChainInterface(\n",
    "        model=ModelType.FLAN_T5_11B,\n",
    "        credentials=Credentials(api_key, api_endpoint=my_api_endpoint),\n",
    "        params=GenerateParams(\n",
    "            decoding_method=\"greedy\",\n",
    "            max_new_tokens=300,\n",
    "            min_new_tokens=15,\n",
    "            repetition_penalty=2,\n",
    "        ).dict()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7c54c",
   "metadata": {},
   "source": [
    "## Loading lang chain qa\n",
    "- creating a chain to get QA from our BAM modles.\n",
    "- Here we are passing chain_type as stuff, which means we are passing all the embeddings fromt the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54de42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(model_llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d486045",
   "metadata": {},
   "source": [
    "## Let' get the embedings for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71062776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "query = \"How to cook eggs\"\n",
    "doc = db.similarity_search(query, k=3)\n",
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83256a",
   "metadata": {},
   "source": [
    "## Finally it's time for us to call our BAM model\n",
    "- here we are passing all embedding and the query to the BAM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ca9a02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cook them until they are just set as they become tough if they are overcooked.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88884dd6",
   "metadata": {},
   "source": [
    "## End of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0982d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
